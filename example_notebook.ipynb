{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker ML Pipeline Example\n",
    "\n",
    "This notebook demonstrates how to use the SageMaker ML pipeline to train, compare, and deploy models.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from pipeline.data_preparation import generate_sample_data, preprocess_for_sagemaker\n",
    "\n",
    "# Generate sample data\n",
    "train_df, test_df, feature_names, target_name = generate_sample_data(use_synthetic=True)\n",
    "\n",
    "print(f\"Training data: {train_df.shape}\")\n",
    "print(f\"Test data: {test_df.shape}\")\n",
    "print(f\"\\nFeatures: {feature_names}\")\n",
    "print(f\"Target: {target_name}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (move target to first column, remove headers)\n",
    "preprocess_for_sagemaker('data/train.csv', 'data/train_processed.csv')\n",
    "preprocess_for_sagemaker('data/test.csv', 'data/test_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up Training (Mock Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.training import ModelTrainer\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = ModelTrainer(bucket='my-sagemaker-bucket', prefix='housing-demo')\n",
    "\n",
    "# Get data paths\n",
    "train_path, validation_path = trainer.get_data_paths()\n",
    "print(f\"Training data: {train_path}\")\n",
    "print(f\"Validation data: {validation_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.model_comparison import ModelComparator, create_mock_model_results\n",
    "\n",
    "# Create mock results for demonstration\n",
    "mock_results = create_mock_model_results()\n",
    "\n",
    "# Compare models\n",
    "comparator = ModelComparator()\n",
    "best_model, best_result = comparator.compare_models(mock_results)\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n",
    "print(f\"Metrics: {best_result['metrics']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_pipeline import run_pipeline\n",
    "\n",
    "# Run the complete pipeline in mock mode\n",
    "best_model, model_results = run_pipeline(\n",
    "    bucket='my-sagemaker-bucket',\n",
    "    prefix='housing-demo',\n",
    "    models=['xgboost', 'knn', 'sklearn-gbm'],\n",
    "    mock_training=True,  # Use mock for demonstration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load comparison results\n",
    "with open('model_comparison.json', 'r') as f:\n",
    "    comparison = json.load(f)\n",
    "\n",
    "# Extract metrics for visualization\n",
    "models = []\n",
    "metrics = []\n",
    "for model_name, result in comparison['all_models'].items():\n",
    "    models.append(model_name)\n",
    "    model_metrics = result['metrics']\n",
    "    # Get the first metric value (simplified)\n",
    "    metric_val = list(model_metrics.values())[0]\n",
    "    metrics.append(metric_val)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, metrics, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Error Metric')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.axhline(y=min(metrics), color='r', linestyle='--', label='Best')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest performing model: {comparison['best_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "To run this with actual SageMaker training:\n",
    "\n",
    "1. Set up AWS credentials\n",
    "2. Deploy CDK infrastructure: `cd src/cdk && cdk deploy`\n",
    "3. Run pipeline with `--no-mock` flag: `python src/run_pipeline.py --bucket <your-bucket> --no-mock`\n",
    "4. Enable hyperparameter tuning with `--tune` flag\n",
    "5. Deploy for batch inference with `--deploy` flag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
